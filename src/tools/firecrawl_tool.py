"""Firecrawl ç½‘é¡µçˆ¬å–å·¥å…·ï¼šæ™ºèƒ½æå–ç½‘é¡µå†…å®¹ã€‚"""

from __future__ import annotations

from typing import Any

from config.settings import settings


def scrape_url(url: str, formats: list[str] = None) -> str:
    """ä½¿ç”¨ Firecrawl çˆ¬å–ç½‘é¡µå†…å®¹ã€‚
    
    å‚æ•°ï¼š
        url: è¦çˆ¬å–çš„ç½‘é¡µ URL
        formats: è¿”å›æ ¼å¼åˆ—è¡¨ï¼Œå¦‚ ['markdown', 'html', 'text']
    
    è¿”å›ï¼š
        æ ¼å¼åŒ–çš„ç½‘é¡µå†…å®¹
    """
    if not settings.firecrawl_api_key:
        return "âŒ é”™è¯¯ï¼šæœªé…ç½® FIRECRAWL_API_KEYï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ "
    
    if formats is None:
        formats = ["markdown"]
    
    try:
        from firecrawl import FirecrawlApp
        
        app = FirecrawlApp(api_key=settings.firecrawl_api_key)
        
        # çˆ¬å–é¡µé¢ï¼ˆæœ€æ–° API ç›´æ¥ä¼ é€’æ ¼å¼å‚æ•°ï¼‰
        result = app.scrape(url, formats=formats)
        
        # æ ¼å¼åŒ–è¾“å‡º
        outputs = []
        outputs.append(f"ğŸ”— URL: {url}\n")
        
        # å¤„ç†è¿”å›çš„ Document å¯¹è±¡
        markdown_content = None
        metadata = {}
        
        # æ–°ç‰ˆ API è¿”å› Document å¯¹è±¡ï¼Œç›´æ¥è®¿é—®å±æ€§
        if hasattr(result, 'markdown'):
            markdown_content = result.markdown
        elif hasattr(result, 'html'):
            markdown_content = result.html
        elif isinstance(result, dict):
            # å…¼å®¹æ—§ç‰ˆ API
            data = result.get("data", result)
            markdown_content = data.get("markdown") or data.get("content") or data.get("text")
            metadata = data.get("metadata", {})
        else:
            markdown_content = str(result)
        
        # æå–å…ƒæ•°æ®
        if hasattr(result, 'metadata') and result.metadata:
            metadata = result.metadata if isinstance(result.metadata, dict) else {}
        
        # æ·»åŠ æ ‡é¢˜å’Œæè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
        if metadata:
            if "title" in metadata:
                outputs.append(f"ğŸ“Œ æ ‡é¢˜: {metadata['title']}")
            if "description" in metadata:
                outputs.append(f"ğŸ“ æè¿°: {metadata['description']}\n")
        
        # æ·»åŠ å†…å®¹
        if markdown_content:
            content = str(markdown_content)[:1000]  # é™åˆ¶é•¿åº¦
            outputs.append("ï¿½ å†…å®¹:")
            outputs.append(content)
            if len(str(markdown_content)) > 1000:
                outputs.append("\n... (å†…å®¹å·²æˆªæ–­)")
        
        return "\n".join(outputs) if outputs else "âš ï¸ æœªæå–åˆ°å†…å®¹"
    
    except ImportError:
        return "âŒ é”™è¯¯ï¼šæœªå®‰è£… firecrawl-py åŒ…ï¼Œè¯·è¿è¡Œ: pip install firecrawl-py"
    
    except Exception as e:
        return f"âŒ çˆ¬å–å¤±è´¥: {str(e)}"


def scrape_multiple_urls(urls: list[str]) -> dict[str, Any]:
    """æ‰¹é‡çˆ¬å–å¤šä¸ª URLã€‚
    
    å‚æ•°ï¼š
        urls: URL åˆ—è¡¨
    
    è¿”å›ï¼š
        åŒ…å«æ‰€æœ‰çˆ¬å–ç»“æœçš„å­—å…¸
    """
    results = {}
    for url in urls:
        results[url] = scrape_url(url)
    return results
