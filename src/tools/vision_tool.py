"""è§†è§‰è¯†åˆ«å·¥å…·ï¼šä½¿ç”¨LLMç†è§£å›¾ç‰‡å†…å®¹ã€‚"""

from __future__ import annotations

import base64
from pathlib import Path
from typing import Optional

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

from config.settings import settings


def encode_image(image_path: str) -> tuple[str, str]:
    """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64å¹¶æ£€æµ‹MIMEç±»å‹ã€‚
    
    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„ï¼‰
        
    Returns:
        (base64_string, mime_type)
    """
    # å¤„ç†è·¯å¾„ï¼šæ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„
    path = Path(image_path)
    
    # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ä½œä¸ºç›¸å¯¹è·¯å¾„
    if not path.exists():
        # å°è¯•ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•
        project_root = Path(__file__).parent.parent.parent
        relative_path = project_root / image_path
        if relative_path.exists():
            path = relative_path
        else:
            # å°è¯•ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„è·¯å¾„ï¼ˆå¯èƒ½æ˜¯ç»å¯¹è·¯å¾„ä½†æ ¼å¼é—®é¢˜ï¼‰
            path = Path(image_path).resolve()
            if not path.exists():
                raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path} (å°è¯•äº†: {path})")
    
    # æ£€æµ‹MIMEç±»å‹
    suffix = path.suffix.lower()
    mime_map = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp'
    }
    mime_type = mime_map.get(suffix, 'image/jpeg')
    
    # è¯»å–å¹¶ç¼–ç 
    with open(path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode('utf-8')
    
    return image_data, mime_type


def analyze_image(
    image_path: str,
    question: Optional[str] = None,
) -> str:
    """ä½¿ç”¨è§†è§‰æ¨¡å‹åˆ†æå›¾ç‰‡å†…å®¹ã€‚
    
    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        question: å¯é€‰çš„å…·ä½“é—®é¢˜ï¼Œå¦‚æœä¸æä¾›åˆ™è¿›è¡Œé€šç”¨æè¿°
        
    Returns:
        å›¾ç‰‡åˆ†æç»“æœ
        
    Examples:
        >>> analyze_image("photo.jpg")
        "è¿™æ˜¯ä¸€å¼ æµ·æ»©æ—¥è½çš„ç…§ç‰‡..."
        
        >>> analyze_image("chart.png", "å›¾è¡¨æ˜¾ç¤ºäº†ä»€ä¹ˆè¶‹åŠ¿ï¼Ÿ")
        "æ ¹æ®å›¾è¡¨ï¼Œæ•°æ®å‘ˆç°ä¸Šå‡è¶‹åŠ¿..."
    """
    try:
        # æ¸…ç†è·¯å¾„ï¼ˆç§»é™¤å¯èƒ½çš„å¼•å·ï¼‰
        if isinstance(image_path, str):
            image_path = image_path.strip("'\"")
        
        # ç¼–ç å›¾ç‰‡
        image_data, mime_type = encode_image(image_path)
        
        # æ„å»ºæç¤ºè¯
        if question:
            prompt = question
        else:
            prompt = "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦ç‰©ä½“ã€åœºæ™¯ã€æ–‡å­—ï¼ˆå¦‚æœ‰ï¼‰ã€é¢œè‰²ã€æ„å›¾ç­‰å…³é”®ä¿¡æ¯ã€‚"
        
        # åˆå§‹åŒ–è§†è§‰æ¨¡å‹
        if not settings.openrouter_api_key:
            return "âŒ é”™è¯¯ï¼šæœªé…ç½® OpenRouter API Keyï¼Œæ— æ³•ä½¿ç”¨è§†è§‰è¯†åˆ«åŠŸèƒ½"
        
        # ä¸´æ—¶ç¦ç”¨ä»£ç†ï¼ˆé¿å…Mihomoå¹²æ‰°OpenRouter APIï¼‰
        import os
        old_http_proxy = os.environ.pop('HTTP_PROXY', None)
        old_https_proxy = os.environ.pop('HTTPS_PROXY', None)
        
        try:
            llm = ChatOpenAI(
                model="anthropic/claude-3.5-sonnet",  # Claude 3.5 æ”¯æŒè§†è§‰
                api_key=settings.openrouter_api_key,
                base_url="https://openrouter.ai/api/v1",
                temperature=0.3,
                max_tokens=1024,
                request_timeout=30,
                default_headers={
                    "HTTP-Referer": "https://maxai.cc",
                    "X-Title": "Max AI Agent - Vision"
                }
            )
            
            # æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯
            message = HumanMessage(
                content=[
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{image_data}"
                        }
                    }
                ]
            )
            
            # è°ƒç”¨æ¨¡å‹
            response = llm.invoke([message])
            
            return f"ğŸ“¸ å›¾ç‰‡åˆ†æç»“æœï¼š\n{response.content}"
        finally:
            # æ¢å¤ä»£ç†è®¾ç½®
            if old_http_proxy:
                os.environ['HTTP_PROXY'] = old_http_proxy
            if old_https_proxy:
                os.environ['HTTPS_PROXY'] = old_https_proxy
        
    except FileNotFoundError as e:
        return f"âŒ é”™è¯¯ï¼š{e}"
    except Exception as e:
        return f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼š{type(e).__name__}: {str(e)}"


# LangChain å·¥å…·åŒ…è£…
if __name__ != "__main__":
    from langchain_core.tools import StructuredTool
    
    vision_analysis = StructuredTool.from_function(
        func=analyze_image,
        name="vision_analysis",
        description="""ä½¿ç”¨AIè§†è§‰æ¨¡å‹åˆ†æå›¾ç‰‡å†…å®¹ã€‚
        
é€‚ç”¨åœºæ™¯ï¼š
- è¯†åˆ«å›¾ç‰‡ä¸­çš„ç‰©ä½“ã€äººç‰©ã€åœºæ™¯
- è¯»å–å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼ˆOCRï¼‰
- åˆ†æå›¾è¡¨ã€è¡¨æ ¼ã€æˆªå›¾
- å›ç­”å…³äºå›¾ç‰‡çš„å…·ä½“é—®é¢˜
- æè¿°ç…§ç‰‡ã€æ’å›¾ã€ç¤ºæ„å›¾

è¾“å…¥ï¼š
- image_pathï¼ˆå¿…éœ€ï¼‰ï¼šå›¾ç‰‡æ–‡ä»¶è·¯å¾„
- questionï¼ˆå¯é€‰ï¼‰ï¼šå…³äºå›¾ç‰‡çš„å…·ä½“é—®é¢˜

ç¤ºä¾‹ï¼š
- analyze_image("screenshot.png") - é€šç”¨æè¿°
- analyze_image("chart.jpg", "è¿™ä¸ªå›¾è¡¨çš„ä¸»è¦è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ") - é’ˆå¯¹æ€§åˆ†æ
        """,
    )
