"""å‘½ä»¤è¡Œä¸»ç¨‹åºï¼šæ”¯æŒæ–‡æœ¬å’Œå¤šæ¨¡æ€è¾“å…¥ã€‚"""

from __future__ import annotations

import argparse
import base64
import sys
from io import BytesIO
from pathlib import Path

try:
    from PIL import Image
except ImportError:
    Image = None

from langchain_core.messages import HumanMessage

from orchestrator.graph import create_graph
from agent.state import init_state


def load_image(image_path: str) -> str | None:
    """åŠ è½½å›¾åƒå¹¶è½¬æ¢ä¸º Base64ã€‚
    
    å‚æ•°ï¼š
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
    
    è¿”å›ï¼š
        Base64 ç¼–ç çš„å›¾åƒï¼Œæˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
    """
    if not Image:
        print("âš ï¸ PIL æœªå®‰è£…ï¼Œæ— æ³•åŠ è½½å›¾åƒã€‚è¯·è¿è¡Œ: pip install pillow")
        return None
    
    try:
        img_path = Path(image_path)
        if not img_path.exists():
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return None
        
        with Image.open(img_path) as img:
            # é™åˆ¶å¤§å°ï¼ˆé¿å…è¿‡å¤§ï¼‰
            max_size = (1024, 1024)
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # è½¬æ¢ä¸º JPEG å¹¶ç¼–ç 
            buffer = BytesIO()
            img.convert("RGB").save(buffer, format="JPEG", quality=85)
            img_bytes = buffer.getvalue()
            
            return base64.b64encode(img_bytes).decode("utf-8")
    
    except Exception as e:
        print(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
        return None


def run_interactive():
    """äº¤äº’å¼æ¨¡å¼ï¼šæŒç»­å¯¹è¯ã€‚"""
    print("ğŸ¤– Max AI Agent å¯åŠ¨ï¼ˆè¾“å…¥ 'exit' é€€å‡ºï¼‰")
    print("=" * 60)
    
    graph = create_graph()
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ä½ : ").strip()
            
            if user_input.lower() in ["exit", "quit", "q"]:
                print("ğŸ‘‹ å†è§ï¼")
                break
            
            if not user_input:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾åƒè·¯å¾„ï¼ˆç®€å•å®ç°ï¼‰
            images = []
            if user_input.startswith("[img:"):
                # æ ¼å¼: [img:path/to/image.jpg] æè¿°æ–‡æœ¬
                parts = user_input.split("]", 1)
                img_path = parts[0][5:].strip()
                user_input = parts[1].strip() if len(parts) > 1 else "è¯·åˆ†æè¿™å¼ å›¾ç‰‡"
                
                img_base64 = load_image(img_path)
                if img_base64:
                    images.append(img_base64)
            
            # åˆå§‹åŒ–çŠ¶æ€
            state = init_state(user_input, images)
            
            print("\n" + "=" * 60)
            print("ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡...")
            print("=" * 60)
            
            # FastAgent æ‰§è¡Œ
            result = graph.invoke(state)
            
            # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
            final_answer = result.get("final_answer", "")
            print(f"\nğŸ’¬ AI: {final_answer}")
            
            # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
            total_time = result.get("total_time_ms", 0)
            llm_calls = result.get("llm_calls", 0)
            success_rate = result.get("success_rate", "N/A")
            
            print(f"\nğŸ“Š æ€§èƒ½: {total_time}ms | LLM: {llm_calls}æ¬¡ | æˆåŠŸç‡: {success_rate}")
            
            print("\n" + "=" * 60)
            print("âœ… ä»»åŠ¡å®Œæˆ")
        
        except KeyboardInterrupt:
            print("\n\nâ¸ï¸ ä»»åŠ¡ä¸­æ–­")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")


def run_once(query: str, image_path: str | None = None):
    """å•æ¬¡æ‰§è¡Œæ¨¡å¼ã€‚
    
    å‚æ•°ï¼š
        query: ç”¨æˆ·æŸ¥è¯¢
        image_path: å¯é€‰çš„å›¾åƒè·¯å¾„
    """
    images = []
    if image_path:
        img_base64 = load_image(image_path)
        if img_base64:
            images.append(img_base64)
    
    state = init_state(query, images)
    graph = create_graph()
    
    print("ğŸš€ æ‰§è¡Œä»»åŠ¡...")
    print("=" * 60)
    
    # FastAgent æ‰§è¡Œ
    result = graph.invoke(state)
    
    print(f"\næœ€ç»ˆç­”æ¡ˆ:\n{result.get('final_answer', '')}")
    print(f"\næ€§èƒ½: {result.get('total_time_ms', 0)}ms | LLM: {result.get('llm_calls', 0)}æ¬¡")
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆ")
    
    return result


def main():
    """ä¸»å…¥å£ã€‚"""
    parser = argparse.ArgumentParser(
        description="Max AI Agent - æ™ºèƒ½ä»»åŠ¡æ‰§è¡ŒåŠ©æ‰‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # äº¤äº’æ¨¡å¼
  python src/main.py

  # å•æ¬¡æŸ¥è¯¢
  python src/main.py --query "æœç´¢æœ€æ–°çš„ AI æ–°é—»"

  # å¸¦å›¾åƒçš„æŸ¥è¯¢
  python src/main.py --query "åˆ†æè¿™å¼ å›¾ç‰‡" --image path/to/image.jpg
        """,
    )
    
    parser.add_argument(
        "-q", "--query",
        type=str,
        help="å•æ¬¡æŸ¥è¯¢ï¼ˆä¸æä¾›åˆ™è¿›å…¥äº¤äº’æ¨¡å¼ï¼‰"
    )
    
    parser.add_argument(
        "-i", "--image",
        type=str,
        help="å›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼‰"
    )
    
    parser.add_argument(
        "--no-stream",
        action="store_true",
        help="ç¦ç”¨æµå¼è¾“å‡º"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®
    from config.settings import settings
    if not settings.openrouter_api_key:
        print("âš ï¸ è­¦å‘Š: OPENROUTER_API_KEY æœªé…ç½®")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENROUTER_API_KEY")
        sys.exit(1)
    
    # æ‰§è¡Œæ¨¡å¼é€‰æ‹©
    if args.query:
        run_once(args.query, args.image)
    else:
        run_interactive()


if __name__ == "__main__":
    main()
