"""é›¶ LLM å¿«é€Ÿè§„åˆ’å™¨ï¼šä½¿ç”¨ NLP + PDDL å®ç°ç¡®å®šæ€§ä»»åŠ¡åˆ†è§£ã€‚

æ€§èƒ½ç›®æ ‡: <120ms
å¹»è§‰é£é™©: 0 (çº¯ç¡®å®šæ€§ç³»ç»Ÿ)
"""

from __future__ import annotations

import re
import time
from typing import List, Dict, Any, Set, Tuple
from dataclasses import dataclass
from enum import Enum


class Intent(Enum):
    """æ„å›¾åˆ†ç±»ï¼ˆè½»é‡çº§ NLPï¼‰"""
    SEARCH = "search"
    CALCULATE = "calculate"
    CODE_EXECUTE = "code_execute"
    FILE_OP = "file_op"
    DATA_ANALYSIS = "data_analysis"
    WEB_SCRAPE = "web_scrape"
    MULTI_STEP = "multi_step"
    SIMPLE_QA = "simple_qa"


@dataclass
class Task:
    """åŸå­ä»»åŠ¡"""
    id: str
    intent: Intent
    tool: str
    params: Dict[str, Any]
    dependencies: Set[str]
    priority: int = 5
    estimated_time_ms: int = 1000


@dataclass
class ExecutionPlan:
    """æ‰§è¡Œè®¡åˆ’ï¼ˆæ ‘ç»“æ„ï¼‰"""
    tasks: List[Task]
    parallel_batches: List[List[str]]  # å¯å¹¶è¡Œæ‰§è¡Œçš„ä»»åŠ¡ ID åˆ†ç»„
    total_estimated_ms: int
    requires_llm_polish: bool = True


class FastPlanner:
    """é›¶ LLM è§„åˆ’å™¨"""
    
    def __init__(self):
        # æ„å›¾è¯†åˆ«è§„åˆ™ï¼ˆç¡®å®šæ€§ï¼‰
        self.intent_patterns = {
            Intent.SEARCH: [
                r"æœç´¢|æŸ¥æ‰¾|æ‰¾ä¸€ä¸‹|æŸ¥è¯¢|search|find",
                r"æœ€æ–°.*ä¿¡æ¯|.*è¿›å±•|.*åŠ¨æ€",
            ],
            Intent.CALCULATE: [
                r"\d+\s*[\+\-\*\/]\s*\d+",
                r"è®¡ç®—|æ±‚å’Œ|æ±‚ç§¯|sum|calculate",
            ],
            Intent.CODE_EXECUTE: [
                r"è¿è¡Œ|æ‰§è¡Œ|ä»£ç |python|javascript",
                r"å†™.*ç¨‹åº|ç”Ÿæˆ.*è„šæœ¬",
            ],
            Intent.FILE_OP: [
                r"è¯»å–|ä¿å­˜|æ–‡ä»¶|file|csv|txt|json",
                r"æ‰“å¼€|å†™å…¥",
            ],
            Intent.DATA_ANALYSIS: [
                r"åˆ†æ|ç»Ÿè®¡|å¯¹æ¯”|è¶‹åŠ¿|analyze",
                r"æ•°æ®.*å¤„ç†|.*å¯è§†åŒ–",
            ],
            Intent.WEB_SCRAPE: [
                r"æŠ“å–|çˆ¬å–|ç½‘é¡µ|scrape|crawl",
                r"æå–.*å†…å®¹",
            ],
            Intent.MULTI_STEP: [
                r"ç„¶å|æ¥ç€|å¹¶ä¸”|åŒæ—¶",
                r"é¦–å…ˆ.*å…¶æ¬¡|ç¬¬ä¸€.*ç¬¬äºŒ",
            ],
        }
        
        # å·¥å…·æ˜ å°„ï¼ˆç¡®å®šæ€§ï¼‰
        self.intent_to_tool = {
            Intent.SEARCH: "intelligent_search",
            Intent.CALCULATE: "code_execution",
            Intent.CODE_EXECUTE: "code_execution",
            Intent.FILE_OP: "file_operations",
            Intent.DATA_ANALYSIS: "data_analysis",
            Intent.WEB_SCRAPE: "file_scraper",
        }
        
        # å‚æ•°æå–è§„åˆ™
        self.param_extractors = {
            Intent.SEARCH: self._extract_search_params,
            Intent.CALCULATE: self._extract_calc_params,
            Intent.FILE_OP: self._extract_file_params,
            Intent.DATA_ANALYSIS: self._extract_analysis_params,
        }
    
    def plan(self, user_query: str, context: Dict[str, Any] = None) -> ExecutionPlan:
        """
        å¿«é€Ÿè§„åˆ’ï¼ˆç›®æ ‡ <120msï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ï¼ˆä¸Šä¼ æ–‡ä»¶ã€å†å²ã€å·¥å…·ç»“æœç­‰ï¼‰
        
        Returns:
            æ‰§è¡Œè®¡åˆ’
        """
        start_time = time.time()
        context = context or {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å†å²ä¸Šä¸‹æ–‡
        has_history = bool(context.get("recent_turns") or context.get("recent_tool_results"))
        if has_history:
            print(f"ğŸ” æ£€æµ‹åˆ°å†å²ä¸Šä¸‹æ–‡ï¼Œå°†çº³å…¥è§„åˆ’")
        
        # 1. æ„å›¾è¯†åˆ«ï¼ˆ10-20msï¼‰
        intents = self._classify_intent(user_query, context)
        
        # 2. ä»»åŠ¡åˆ†è§£ï¼ˆ20-40msï¼‰
        tasks = self._decompose_tasks(user_query, intents, context)
        
        # 3. ä¾èµ–åˆ†æï¼ˆ10-20msï¼‰
        self._analyze_dependencies(tasks)
        
        # 4. PDDL è°ƒåº¦ï¼ˆ30-40msï¼‰
        parallel_batches = self._schedule_tasks(tasks)
        
        # 5. ä¼°ç®—æ€»æ—¶é—´
        total_time = self._estimate_total_time(parallel_batches, tasks)
        
        elapsed_ms = int((time.time() - start_time) * 1000)
        print(f"âš¡ FastPlanner å®Œæˆ: {elapsed_ms}ms")
        
        return ExecutionPlan(
            tasks=tasks,
            parallel_batches=parallel_batches,
            total_estimated_ms=total_time,
            requires_llm_polish=self._needs_polish(intents)
        )
    
    def _classify_intent(self, query: str, context: Dict[str, Any] = None) -> List[Intent]:
        """
        è½»é‡çº§ NLP æ„å›¾åˆ†ç±»ï¼ˆç¡®å®šæ€§ï¼Œ<20msï¼‰
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: å†å²ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        """
        query_lower = query.lower()
        detected_intents = []
        context = context or {}
        
        # æ£€æµ‹ä¸Šä¼ çš„æ–‡ä»¶ç±»å‹ï¼ˆå›¾ç‰‡è‡ªåŠ¨è§¦å‘è§†è§‰åˆ†æï¼Œå…¶ä»–æ–‡ä»¶è§¦å‘æ–‡ä»¶æ“ä½œï¼‰
        uploaded_files = context.get("uploaded_files", [])
        if uploaded_files:
            for file_path in uploaded_files:
                file_lower = file_path.lower()
                # æ£€æµ‹å›¾ç‰‡æ–‡ä»¶
                if any(ext in file_lower for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']):
                    print(f"[IMAGE] æ£€æµ‹åˆ°å›¾ç‰‡æ–‡ä»¶: {file_path}")
                    # å¦‚æœæŸ¥è¯¢ä¸­æ²¡æœ‰æ˜ç¡®çš„å…¶ä»–æ„å›¾ï¼Œé»˜è®¤ä¸ºå›¾ç‰‡åˆ†æ
                    if not any(keyword in query_lower for keyword in ['æœç´¢', 'è®¡ç®—', 'ä»£ç ', 'æ‰§è¡Œ']):
                        # åˆ›å»ºç‰¹æ®Šçš„å›¾ç‰‡åˆ†ææ„å›¾ï¼ˆåç»­ä¼šæ˜ å°„åˆ°vision_analysiså·¥å…·ï¼‰
                        detected_intents.append(Intent.FILE_OP)  # æš‚æ—¶ç”¨FILE_OPï¼Œåé¢ç‰¹æ®Šå¤„ç†
                        break
                # æ£€æµ‹å…¶ä»–æ–‡ä»¶ï¼ˆtxt, docx, pdf ç­‰ï¼‰
                elif any(ext in file_lower for ext in ['.txt', '.docx', '.doc', '.pdf', '.csv', '.json', '.py', '.md', '.html', '.css', '.js']):
                    print(f"[FILE] æ£€æµ‹åˆ°æ–‡ä»¶: {file_path}")
                    # å¦‚æœæœ‰ä¸Šä¼ çš„æ–‡ä»¶ï¼Œè‡ªåŠ¨æ·»åŠ æ–‡ä»¶æ“ä½œæ„å›¾
                    if Intent.FILE_OP not in detected_intents:
                        detected_intents.append(Intent.FILE_OP)
                        print(f"[FILE] è‡ªåŠ¨æ·»åŠ æ–‡ä»¶æ“ä½œæ„å›¾")
                    break
        
        # æ£€æµ‹æ˜¯å¦ä¸ºå»¶ç»­æ€§æŸ¥è¯¢ï¼ˆéœ€è¦å†å²ä¸Šä¸‹æ–‡ï¼‰
        continuation_keywords = ["ç»§ç»­", "æ¥ç€", "ç„¶å", "å†", "è¿˜æœ‰", "ä¸Šé¢", "ä¹‹å‰", "åˆšæ‰"]
        is_continuation = any(kw in query_lower for kw in continuation_keywords)
        
        # å¦‚æœæ˜¯å»¶ç»­æ€§æŸ¥è¯¢ä¸”æœ‰å†å²å·¥å…·ç»“æœï¼Œå¤ç”¨ä¹‹å‰çš„æ„å›¾
        if is_continuation and context.get("recent_turns"):
            recent_turns = context["recent_turns"]
            if recent_turns:
                last_tools = recent_turns[-1].get("tools_used", [])
                print(f"ğŸ”„ æ£€æµ‹åˆ°å»¶ç»­æ€§æŸ¥è¯¢ï¼Œä¸Šæ¬¡ä½¿ç”¨å·¥å…·: {last_tools}")
        
        # è§„åˆ™åŒ¹é…
        for intent, patterns in self.intent_patterns.items():
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    detected_intents.append(intent)
                    print(f"  âœ… æ£€æµ‹åˆ°æ„å›¾: {intent.value} (åŒ¹é…æ¨¡å¼: {pattern})")
                    break
        
        # å¤šæ­¥éª¤æ£€æµ‹
        if Intent.MULTI_STEP in detected_intents:
            detected_intents.remove(Intent.MULTI_STEP)
            # ä¿ç•™å…¶ä»–æ„å›¾ï¼Œæ ‡è®°ä¸ºå¤šæ­¥éª¤
        
        # é»˜è®¤æ„å›¾
        if not detected_intents:
            detected_intents.append(Intent.SIMPLE_QA)
            print(f"  âš ï¸ æœªæ£€æµ‹åˆ°æ˜ç¡®æ„å›¾ï¼Œä½¿ç”¨é»˜è®¤: SIMPLE_QA")
        
        print(f"  ğŸ“‹ æœ€ç»ˆæ£€æµ‹åˆ°çš„æ„å›¾: {[i.value for i in detected_intents]}")
        return detected_intents
    
    def _decompose_tasks(
        self, 
        query: str, 
        intents: List[Intent], 
        context: Dict[str, Any]
    ) -> List[Task]:
        """
        åˆ†è§£ä¸ºåŸå­ä»»åŠ¡ï¼ˆç¡®å®šæ€§ï¼Œ<40msï¼‰
        """
        tasks = []
        task_id = 0
        
        # ç‰¹æ®Šå¤„ç†ï¼šæ£€æµ‹ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ›å»ºvision_analysisä»»åŠ¡
        uploaded_files = context.get("uploaded_files", [])
        image_files = [f for f in uploaded_files if any(ext in f.lower() for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'])]
        
        if image_files:
            for img_path in image_files:
                # æå–æŸ¥è¯¢ä¸­çš„é—®é¢˜ï¼ˆå»æ‰æ–‡ä»¶è·¯å¾„æç¤ºï¼‰
                clean_query = re.sub(r'\[ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶:.*?\]', '', query).strip()
                question = clean_query if clean_query else None
                
                task = Task(
                    id=f"task_{task_id}",
                    intent=Intent.FILE_OP,  # ä½¿ç”¨FILE_OPæ„å›¾ï¼ˆå›¾ç‰‡ä¹Ÿæ˜¯æ–‡ä»¶ï¼‰
                    tool="vision_analysis",
                    params={
                        "image_path": img_path,
                        "question": question
                    },
                    dependencies=set(),
                    priority=1,
                    estimated_time_ms=8000
                )
                tasks.append(task)
                task_id += 1
                print(f"[VISION] åˆ›å»ºå›¾ç‰‡åˆ†æä»»åŠ¡: {img_path}")
        
        # å¤„ç†å…¶ä»–æ„å›¾
        for intent in intents:
            # è·³è¿‡ç®€å•é—®ç­”
            if intent == Intent.SIMPLE_QA:
                print(f"  â­ï¸ è·³è¿‡ç®€å•é—®ç­”æ„å›¾")
                continue
            
            # å¦‚æœå·²ç»å¤„ç†äº†å›¾ç‰‡ï¼Œè·³è¿‡FILE_OPæ„å›¾ï¼ˆé¿å…é‡å¤ï¼‰
            if intent == Intent.FILE_OP and image_files:
                print(f"  â­ï¸ è·³è¿‡æ–‡ä»¶æ“ä½œæ„å›¾ï¼ˆå·²å¤„ç†å›¾ç‰‡ï¼‰")
                continue
            
            # è·å–å·¥å…·
            tool = self.intent_to_tool.get(intent)
            if not tool:
                print(f"  âš ï¸ æ„å›¾ {intent.value} æ²¡æœ‰å¯¹åº”çš„å·¥å…·")
                continue
            
            print(f"  ğŸ”§ ä¸ºæ„å›¾ {intent.value} åˆ›å»ºä»»åŠ¡ï¼Œå·¥å…·: {tool}")
            
            # æå–å‚æ•°ï¼ˆç¡®å®šæ€§ï¼‰
            extractor = self.param_extractors.get(intent, lambda q, c: {})
            params = extractor(query, context)
            
            # åˆ›å»ºä»»åŠ¡
            task = Task(
                id=f"task_{task_id}",
                intent=intent,
                tool=tool,
                params=params,
                dependencies=set(),
                priority=self._get_priority(intent),
                estimated_time_ms=self._estimate_task_time(tool)
            )
            
            tasks.append(task)
            task_id += 1
        
        return tasks
    
    def _extract_search_params(self, query: str, context: Dict) -> Dict[str, Any]:
        """æå–æœç´¢å‚æ•°ï¼ˆç¡®å®šæ€§ï¼‰"""
        # å»é™¤å™ªéŸ³è¯ï¼Œä½†ä¿ç•™æŸ¥è¯¢çš„æ ¸å¿ƒå†…å®¹
        noise_words = ["æœç´¢", "æŸ¥æ‰¾", "æ‰¾ä¸€ä¸‹", "å¸®æˆ‘", "è¯·"]
        clean_query = query
        for word in noise_words:
            # åªç§»é™¤ç‹¬ç«‹çš„è¯ï¼Œé¿å…è¯¯åˆ æŸ¥è¯¢å†…å®¹
            clean_query = re.sub(rf'\b{re.escape(word)}\b', '', clean_query, flags=re.IGNORECASE)
        
        # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢
        clean_query = clean_query.strip() or query.strip()
        
        print(f"  ğŸ” æœç´¢æŸ¥è¯¢: {clean_query}")
        
        return {
            "query": clean_query,
            "max_results": 5
        }
    
    def _extract_calc_params(self, query: str, context: Dict) -> Dict[str, Any]:
        """æå–è®¡ç®—å‚æ•°"""
        # æå–æ•°å­—èŒƒå›´ï¼ˆå¦‚"1åˆ°100"ï¼‰
        range_match = re.search(r'(\d+)\s*(?:åˆ°|è‡³|~|-)\s*(\d+)', query)
        if range_match and any(kw in query for kw in ['å’Œ', 'æ±‚å’Œ', 'sum', 'åŠ ']):
            start, end = range_match.groups()
            code = f"""# è®¡ç®— {start} åˆ° {end} çš„å’Œ
result = sum(range({start}, {end}+1))
print(f"{start} åˆ° {end} çš„å’Œæ˜¯: {{result}}")"""
            return {"code": code}
        
        # æå–æ•°å­¦è¡¨è¾¾å¼
        math_expr = re.search(r'[\d\+\-\*\/\(\)\s]+', query)
        if math_expr:
            expr = math_expr.group().strip()
            code = f"""# è®¡ç®—: {expr}
result = {expr}
print(f"è®¡ç®—ç»“æœ: {{result}}")"""
            return {"code": code}
        
        # å…¶ä»–è®¡ç®—
        numbers = re.findall(r'\d+', query)
        if len(numbers) >= 2:
            code = f"""# æ±‚å’Œ
result = sum([{', '.join(numbers)}])
print(f"ç»“æœ: {{result}}")"""
        else:
            code = f"print('æ— æ³•è¯†åˆ«çš„è®¡ç®—ä»»åŠ¡: {query}')"
        
        return {"code": code}
    
    def _extract_file_params(self, query: str, context: Dict) -> Dict[str, Any]:
        """æå–æ–‡ä»¶æ“ä½œå‚æ•°"""
        # ä»ä¸Šä¸‹æ–‡è·å–æ–‡ä»¶è·¯å¾„
        file_path = None
        if context and "uploaded_files" in context:
            files = context["uploaded_files"]
            if files:
                file_path = files[0]  # å–ç¬¬ä¸€ä¸ªæ–‡ä»¶
                print(f"[FILE] æ£€æµ‹åˆ°ä¸Šä¼ çš„æ–‡ä»¶: {file_path}")
        
        # æˆ–ä»æŸ¥è¯¢ä¸­æå–
        if not file_path:
            file_match = re.search(r'[a-zA-Z0-9_\-]+\.(csv|txt|json|xlsx|pdf|docx|doc)', query)
            if file_match:
                file_path = f"data/uploads/{file_match.group()}"
        
        # æ£€æµ‹æ“ä½œç±»å‹
        # å¦‚æœæœ‰ä¸Šä¼ çš„æ–‡ä»¶ï¼Œé»˜è®¤æ˜¯è¯»å–æ“ä½œ
        if file_path:
            if any(word in query for word in ["ä¿å­˜", "å†™å…¥", "write"]):
                operation = "write"
            else:
                # é»˜è®¤è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
                operation = "read"
                print(f"[FILE] é»˜è®¤æ“ä½œ: è¯»å–æ–‡ä»¶ {file_path}")
        else:
            if any(word in query for word in ["è¯»å–", "æ‰“å¼€", "æŸ¥çœ‹", "read"]):
                operation = "read"
            elif any(word in query for word in ["ä¿å­˜", "å†™å…¥", "write"]):
                operation = "write"
            else:
                operation = "list"
        
        return {
            "operation": operation,
            "file_path": file_path or "data/temp.txt"
        }
    
    def _extract_analysis_params(self, query: str, context: Dict) -> Dict[str, Any]:
        """æå–æ•°æ®åˆ†æå‚æ•°"""
        # ç®€åŒ–ï¼šå‡è®¾éœ€è¦åˆ†æä¸Šä¼ çš„æ–‡ä»¶
        file_path = None
        if context and "uploaded_files" in context:
            files = context["uploaded_files"]
            if files:
                file_path = files[0]
        
        # ç”Ÿæˆåˆ†æä»£ç 
        code = f"""
import pandas as pd
df = pd.read_csv('{file_path}')
print(df.describe())
print(df.head())
"""
        
        return {"code": code.strip()}
    
    def _analyze_dependencies(self, tasks: List[Task]):
        """
        ä¾èµ–åˆ†æï¼ˆç¡®å®šæ€§ï¼Œ<20msï¼‰
        
        è§„åˆ™:
        - æ–‡ä»¶è¯»å– -> æ•°æ®åˆ†æ
        - æœç´¢ -> æ•°æ®åˆ†æ
        - å…¶ä»–ä»»åŠ¡é»˜è®¤æ— ä¾èµ–ï¼ˆå¯å¹¶è¡Œï¼‰
        """
        task_dict = {t.id: t for t in tasks}
        
        for task in tasks:
            if task.intent == Intent.DATA_ANALYSIS:
                # æŸ¥æ‰¾æ–‡ä»¶æ“ä½œä»»åŠ¡
                for other in tasks:
                    if other.intent == Intent.FILE_OP and other.id != task.id:
                        task.dependencies.add(other.id)
    
    def _schedule_tasks(self, tasks: List[Task]) -> List[List[str]]:
        """
        PDDL è°ƒåº¦å™¨ï¼šç”Ÿæˆå¹¶è¡Œæ‰§è¡Œæ‰¹æ¬¡ï¼ˆ<40msï¼‰
        
        Returns:
            [[batch1_tasks], [batch2_tasks], ...]
        """
        if not tasks:
            return []
        
        # æ‹“æ‰‘æ’åº + å¹¶è¡Œä¼˜åŒ–
        task_dict = {t.id: t for t in tasks}
        remaining = set(task_dict.keys())
        batches = []
        
        while remaining:
            # æ‰¾å‡ºå½“å‰å¯æ‰§è¡Œçš„ä»»åŠ¡ï¼ˆæ— ä¾èµ–æˆ–ä¾èµ–å·²å®Œæˆï¼‰
            completed = set(task_dict.keys()) - remaining
            ready = []
            
            for task_id in remaining:
                task = task_dict[task_id]
                if not task.dependencies or task.dependencies.issubset(completed):
                    ready.append(task_id)
            
            if not ready:
                # å¾ªç¯ä¾èµ–ï¼Œå¼ºåˆ¶æ‰§è¡Œ
                ready = list(remaining)
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            ready.sort(key=lambda tid: task_dict[tid].priority, reverse=True)
            
            batches.append(ready)
            remaining -= set(ready)
        
        return batches
    
    def _estimate_total_time(
        self, 
        batches: List[List[str]], 
        tasks: List[Task]
    ) -> int:
        """
        ä¼°ç®—æ€»æ‰§è¡Œæ—¶é—´ï¼ˆå¹¶è¡Œæ‰¹æ¬¡ï¼‰
        """
        task_dict = {t.id: t for t in tasks}
        total_ms = 0
        
        for batch in batches:
            # æ‰¹æ¬¡å†…å¹¶è¡Œï¼Œå–æœ€é•¿æ—¶é—´
            batch_time = max(
                task_dict[tid].estimated_time_ms 
                for tid in batch
            )
            total_ms += batch_time
        
        return total_ms
    
    def _get_priority(self, intent: Intent) -> int:
        """ä»»åŠ¡ä¼˜å…ˆçº§"""
        priority_map = {
            Intent.FILE_OP: 10,       # æœ€é«˜ä¼˜å…ˆçº§
            Intent.SEARCH: 8,
            Intent.WEB_SCRAPE: 8,
            Intent.DATA_ANALYSIS: 5,
            Intent.CODE_EXECUTE: 5,
            Intent.CALCULATE: 3,
        }
        return priority_map.get(intent, 5)
    
    def _estimate_task_time(self, tool: str) -> int:
        """ä¼°ç®—å·¥å…·æ‰§è¡Œæ—¶é—´ï¼ˆmsï¼‰"""
        time_estimates = {
            "intelligent_search": 2000,
            "file_operations": 100,
            "code_execution": 1500,
            "data_analysis": 2000,
            "file_scraper": 3000,
        }
        return time_estimates.get(tool, 1000)
    
    def _needs_polish(self, intents: List[Intent]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ LLM æ¶¦è‰²
        
        FastAgent æ¶æ„è¦æ±‚ï¼šæ‰€æœ‰æŸ¥è¯¢éƒ½éœ€è¦ LLM è¿›è¡Œæœ€ç»ˆå›ç­”
        - ç®€å•é—®ç­”ï¼šLLM ç›´æ¥å›ç­”
        - å·¥å…·ä»»åŠ¡ï¼šLLM æ ¹æ®å·¥å…·ç»“æœè¿›è¡Œæ¶¦è‰²å’Œæ•´åˆ
        """
        # æ‰€æœ‰æŸ¥è¯¢éƒ½éœ€è¦ LLM å‚ä¸
        return True


# å…¨å±€å•ä¾‹
fast_planner = FastPlanner()
